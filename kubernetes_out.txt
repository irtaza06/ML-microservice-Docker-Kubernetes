$ ./run_kubernetes.sh 
pod/kubernetes-predictionapp created
NAME                       READY   STATUS              RESTARTS   AGE
kubernetes-predictionapp   0/1     ContainerCreating   0          0s
Name:         kubernetes-predictionapp
Namespace:    default
Priority:     0
Node:         minikube/192.168.39.199
Start Time:   Mon, 18 May 2020 11:16:08 +0200
Labels:       run=kubernetes-predictionapp
Annotations:  <none>
Status:       Pending
IP:           
IPs:          <none>
Containers:
  kubernetes-predictionapp:
    Container ID:   
    Image:          irtaza06/predictionapp:test
    Image ID:       
    Port:           <none>
    Host Port:      <none>
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-8pb7p (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  default-token-8pb7p:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-8pb7p
    Optional:    false
QoS Class:       BestEffort
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type    Reason     Age        From               Message
  ----    ------     ----       ----               -------
  Normal  Scheduled  <unknown>  default-scheduler  Successfully assigned default/kubernetes-predictionapp to minikube
Forwarding from 127.0.0.1:5000 -> 80
Forwarding from [::1]:5000 -> 80
Handling connection for 5000
Handling connection for 5000
Handling connection for 5000
Handling connection for 5000





prediction value from the output of make_prediction.sh from another terminal tab:

---------------------------------------------------
$ ./make_prediction.sh 
Port: 5000
{
  "prediction": [
    20.35373177134412
  ]
}
--------------------------------------------------

or using kubectl logs pods/kubenetes-predictionapp

-------------------------------------------------
irtaza06 (master *) project-ml-microservice-kubernetes
$ kubectl logs pods/kubernetes-predictionapp 
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 108-117-829
127.0.0.1 - - [18/May/2020 20:10:27] "GET / HTTP/1.1" 200 -
127.0.0.1 - - [18/May/2020 20:10:27] "GET /favicon.ico HTTP/1.1" 404 -
[2020-05-18 20:12:40,061] INFO in app: JSON payload: 
{'CHAS': {'0': 0}, 'RM': {'0': 6.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2020-05-18 20:12:40,079] INFO in app: Inference payload DataFrame: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2020-05-18 20:12:40,087] INFO in app: Scaling Payload: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  6.575  296.0     15.3  396.9   4.98
[2020-05-18 20:12:40,090] INFO in app: Output prediction value: 
[20.35373177134412]
127.0.0.1 - - [18/May/2020 20:12:40] "POST /predict HTTP/1.1" 200 -
-----------------------------------------------------------------------
